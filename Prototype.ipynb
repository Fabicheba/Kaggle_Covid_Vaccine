{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cols = ['reactivity', 'deg_Mg_pH10', 'deg_Mg_50C', 'deg_pH10', 'deg_50C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cols = ['sequence', 'structure', 'predicted_loop_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_json('train.json', lines=True)\n",
    "test = pd.read_json('test.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.query(\"signal_to_noise >= 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.query(\"SN_filter == 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_private = test.query(\"seq_length == 130\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_public = test.query(\"seq_length == 107\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_inputs(df,input_cols):\n",
    "    \"\"\"\n",
    "    Converts inputs into one-hot\n",
    "    \"\"\"\n",
    "    output = []\n",
    "    for i in range(len(input_cols)):\n",
    "        tokenizer = keras.preprocessing.text.Tokenizer(char_level=True)\n",
    "        tokenizer.fit_on_texts(np.asarray(df[input_cols[i]]))\n",
    "        tmp = tokenizer.texts_to_sequences(np.asarray(df[input_cols[i]]))\n",
    "        output.append(np.asarray(keras.utils.to_categorical(tmp)[:,:,1:]))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = preprocess_inputs(train,input_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1587"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_inputs(inputs, length):\n",
    "    \"\"\"\n",
    "    Merges the one-hot inputs by columns\n",
    "    Also snips seq length's till desired amount\n",
    "    \"\"\"\n",
    "    size = len(inputs[0])\n",
    "    output = []\n",
    "    for i in range(size):\n",
    "        output.append(np.concatenate((inputs[0][i][0:length], inputs[1][i][0:length], inputs[2][i][0:length]), axis = 1))\n",
    "    return np.asarray(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_simple = merge_inputs(inputs, 68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1587, 68, 14)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_simple.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = np.zeros((2,5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1[1,1,0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_results(df, results):\n",
    "    \"\"\"\n",
    "    Makes sure that the results are in the appropriate format:\n",
    "        [layers,lines,columns] in an np array\n",
    "    \"\"\"\n",
    "    tmp = np.asarray(df[results])\n",
    "    size = len(tmp[0])\n",
    "    output = np.zeros((len(tmp),len(tmp[0][0]),len(results)))\n",
    "    for i in range(len(results)):\n",
    "        for j in range(size):\n",
    "            tmp[i,j] = np.asarray(tmp[i,j])\n",
    "    for i in range(len(tmp)):\n",
    "        output[i] = np.vstack((tmp[i,0], tmp[i,1], tmp[i,2], \n",
    "                                tmp[i,3], tmp[i,4]))[:,:].T\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_results = preprocess_results(train, pred_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1587, 68, 5)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3297, 0.7556, 0.3581, 2.3375, 0.6382])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_results[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, None, 10)          430       \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                336       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                170       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 68)                748       \n",
      "=================================================================\n",
      "Total params: 1,904\n",
      "Trainable params: 1,904\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_simple = keras.Sequential()\n",
    "\n",
    "model_simple.add(keras.layers.Conv1D(filters=10, kernel_size=3, activation=('relu'), \n",
    "                                     input_shape=(None,14), padding='same'))\n",
    "model_simple.add(keras.layers.GlobalMaxPooling1D())\n",
    "model_simple.add(keras.layers.Dense(20, activation=('relu')))\n",
    "model_simple.add(keras.layers.Dense(16, activation='relu'))\n",
    "model_simple.add(keras.layers.Dropout(rate=0.4))\n",
    "model_simple.add(keras.layers.Dense(10, activation='relu'))\n",
    "\n",
    "\n",
    "#Est-ce que le out put c'est 3 valuers distinctes, ou 1 valeurs mais qui existe dans 3 channels?\n",
    "model_simple.add(keras.layers.Dense(68, activation='linear'))\n",
    "\n",
    "# mean_squared_error car on a affair a une regression\n",
    "model_simple.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_squared_error'])\n",
    "model_simple.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "20/20 [==============================] - 0s 23ms/step - loss: 0.3338 - mean_squared_error: 0.3338 - val_loss: 0.3172 - val_mean_squared_error: 0.3172\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.2960 - mean_squared_error: 0.2960 - val_loss: 0.2798 - val_mean_squared_error: 0.2798\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.2649 - mean_squared_error: 0.2649 - val_loss: 0.2481 - val_mean_squared_error: 0.2481\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.2375 - mean_squared_error: 0.2375 - val_loss: 0.2241 - val_mean_squared_error: 0.2241\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.2127 - mean_squared_error: 0.2127 - val_loss: 0.2059 - val_mean_squared_error: 0.2059\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.1966 - mean_squared_error: 0.1966 - val_loss: 0.1907 - val_mean_squared_error: 0.1907\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.1846 - mean_squared_error: 0.1846 - val_loss: 0.1815 - val_mean_squared_error: 0.1815\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.1781 - mean_squared_error: 0.1781 - val_loss: 0.1775 - val_mean_squared_error: 0.1775\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.1727 - mean_squared_error: 0.1727 - val_loss: 0.1739 - val_mean_squared_error: 0.1739\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 23ms/step - loss: 0.1706 - mean_squared_error: 0.1706 - val_loss: 0.1749 - val_mean_squared_error: 0.1749\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.1682 - mean_squared_error: 0.1682 - val_loss: 0.1746 - val_mean_squared_error: 0.1746\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.1665 - mean_squared_error: 0.1665 - val_loss: 0.1716 - val_mean_squared_error: 0.1716\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.1663 - mean_squared_error: 0.1663 - val_loss: 0.1719 - val_mean_squared_error: 0.1719\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.1653 - mean_squared_error: 0.1653 - val_loss: 0.1720 - val_mean_squared_error: 0.1720\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.1649 - mean_squared_error: 0.1649 - val_loss: 0.1708 - val_mean_squared_error: 0.1708\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.1639 - mean_squared_error: 0.1639 - val_loss: 0.1730 - val_mean_squared_error: 0.1730\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.1634 - mean_squared_error: 0.1634 - val_loss: 0.1723 - val_mean_squared_error: 0.1723\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.1624 - mean_squared_error: 0.1624 - val_loss: 0.1727 - val_mean_squared_error: 0.1727\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.1623 - mean_squared_error: 0.1623 - val_loss: 0.1725 - val_mean_squared_error: 0.1725\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.1618 - mean_squared_error: 0.1618 - val_loss: 0.1722 - val_mean_squared_error: 0.1722\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.1613 - mean_squared_error: 0.1613 - val_loss: 0.1721 - val_mean_squared_error: 0.1721\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.1612 - mean_squared_error: 0.1612 - val_loss: 0.1729 - val_mean_squared_error: 0.1729\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.1613 - mean_squared_error: 0.1613 - val_loss: 0.1724 - val_mean_squared_error: 0.1724\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.1608 - mean_squared_error: 0.1608 - val_loss: 0.1717 - val_mean_squared_error: 0.1717\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.1605 - mean_squared_error: 0.1605 - val_loss: 0.1716 - val_mean_squared_error: 0.1716\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.1605 - mean_squared_error: 0.1605 - val_loss: 0.1726 - val_mean_squared_error: 0.1726\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.1601 - mean_squared_error: 0.1601 - val_loss: 0.1713 - val_mean_squared_error: 0.1713\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.1602 - mean_squared_error: 0.1602 - val_loss: 0.1718 - val_mean_squared_error: 0.1718\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.1601 - mean_squared_error: 0.1601 - val_loss: 0.1718 - val_mean_squared_error: 0.1718\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.1598 - mean_squared_error: 0.1598 - val_loss: 0.1708 - val_mean_squared_error: 0.1708\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.1595 - mean_squared_error: 0.1595 - val_loss: 0.1716 - val_mean_squared_error: 0.1716\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.1592 - mean_squared_error: 0.1592 - val_loss: 0.1700 - val_mean_squared_error: 0.1700\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.1594 - mean_squared_error: 0.1594 - val_loss: 0.1694 - val_mean_squared_error: 0.1694\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.1592 - mean_squared_error: 0.1592 - val_loss: 0.1690 - val_mean_squared_error: 0.1690\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.1590 - mean_squared_error: 0.1590 - val_loss: 0.1696 - val_mean_squared_error: 0.1696\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.1591 - mean_squared_error: 0.1591 - val_loss: 0.1686 - val_mean_squared_error: 0.1686\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.1591 - mean_squared_error: 0.1591 - val_loss: 0.1685 - val_mean_squared_error: 0.1685\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.1591 - mean_squared_error: 0.1591 - val_loss: 0.1682 - val_mean_squared_error: 0.1682\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.1587 - mean_squared_error: 0.1587 - val_loss: 0.1686 - val_mean_squared_error: 0.1686\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.1587 - mean_squared_error: 0.1587 - val_loss: 0.1686 - val_mean_squared_error: 0.1686\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.1588 - mean_squared_error: 0.1588 - val_loss: 0.1685 - val_mean_squared_error: 0.1685\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.1585 - mean_squared_error: 0.1585 - val_loss: 0.1689 - val_mean_squared_error: 0.1689\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.1586 - mean_squared_error: 0.1586 - val_loss: 0.1681 - val_mean_squared_error: 0.1681\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.1584 - mean_squared_error: 0.1584 - val_loss: 0.1691 - val_mean_squared_error: 0.1691\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.1583 - mean_squared_error: 0.1583 - val_loss: 0.1686 - val_mean_squared_error: 0.1686\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.1585 - mean_squared_error: 0.1585 - val_loss: 0.1673 - val_mean_squared_error: 0.1673\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.1584 - mean_squared_error: 0.1584 - val_loss: 0.1675 - val_mean_squared_error: 0.1675\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.1578 - mean_squared_error: 0.1578 - val_loss: 0.1689 - val_mean_squared_error: 0.1689\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.1579 - mean_squared_error: 0.1579 - val_loss: 0.1687 - val_mean_squared_error: 0.1687\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.1578 - mean_squared_error: 0.1578 - val_loss: 0.1692 - val_mean_squared_error: 0.1692\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 7ms/step - loss: 0.1576 - mean_squared_error: 0.1576 - val_loss: 0.1684 - val_mean_squared_error: 0.1684\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.1573 - mean_squared_error: 0.1573 - val_loss: 0.1670 - val_mean_squared_error: 0.1670\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.1574 - mean_squared_error: 0.1574 - val_loss: 0.1672 - val_mean_squared_error: 0.1672\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.1568 - mean_squared_error: 0.1568 - val_loss: 0.1680 - val_mean_squared_error: 0.1680\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.1570 - mean_squared_error: 0.1570 - val_loss: 0.1676 - val_mean_squared_error: 0.1676\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.1568 - mean_squared_error: 0.1568 - val_loss: 0.1671 - val_mean_squared_error: 0.1671\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.1564 - mean_squared_error: 0.1564 - val_loss: 0.1666 - val_mean_squared_error: 0.1666\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.1566 - mean_squared_error: 0.1566 - val_loss: 0.1673 - val_mean_squared_error: 0.1673\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.1561 - mean_squared_error: 0.1561 - val_loss: 0.1674 - val_mean_squared_error: 0.1674\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.1562 - mean_squared_error: 0.1562 - val_loss: 0.1666 - val_mean_squared_error: 0.1666\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.1559 - mean_squared_error: 0.1559 - val_loss: 0.1679 - val_mean_squared_error: 0.1679\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.1556 - mean_squared_error: 0.1556 - val_loss: 0.1678 - val_mean_squared_error: 0.1678\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.1556 - mean_squared_error: 0.1556 - val_loss: 0.1676 - val_mean_squared_error: 0.1676\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.1555 - mean_squared_error: 0.1555 - val_loss: 0.1670 - val_mean_squared_error: 0.1670\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.1551 - mean_squared_error: 0.1551 - val_loss: 0.1664 - val_mean_squared_error: 0.1664\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.1552 - mean_squared_error: 0.1552 - val_loss: 0.1668 - val_mean_squared_error: 0.1668\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.1549 - mean_squared_error: 0.1549 - val_loss: 0.1671 - val_mean_squared_error: 0.1671\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.1545 - mean_squared_error: 0.1545 - val_loss: 0.1658 - val_mean_squared_error: 0.1658\n",
      "Epoch 69/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.1548 - mean_squared_error: 0.1548 - val_loss: 0.1649 - val_mean_squared_error: 0.1649\n",
      "Epoch 70/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.1545 - mean_squared_error: 0.1545 - val_loss: 0.1661 - val_mean_squared_error: 0.1661\n",
      "Epoch 71/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.1546 - mean_squared_error: 0.1546 - val_loss: 0.1646 - val_mean_squared_error: 0.1646\n",
      "Epoch 72/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.1543 - mean_squared_error: 0.1543 - val_loss: 0.1650 - val_mean_squared_error: 0.1650\n",
      "Epoch 73/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.1545 - mean_squared_error: 0.1545 - val_loss: 0.1653 - val_mean_squared_error: 0.1653\n",
      "Epoch 74/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.1540 - mean_squared_error: 0.1540 - val_loss: 0.1650 - val_mean_squared_error: 0.1650\n",
      "Epoch 75/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.1539 - mean_squared_error: 0.1539 - val_loss: 0.1650 - val_mean_squared_error: 0.1650\n",
      "Epoch 76/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.1541 - mean_squared_error: 0.1541 - val_loss: 0.1645 - val_mean_squared_error: 0.1645\n",
      "Epoch 77/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.1540 - mean_squared_error: 0.1540 - val_loss: 0.1651 - val_mean_squared_error: 0.1651\n",
      "Epoch 78/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.1538 - mean_squared_error: 0.1538 - val_loss: 0.1653 - val_mean_squared_error: 0.1653\n",
      "Epoch 79/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.1535 - mean_squared_error: 0.1535 - val_loss: 0.1645 - val_mean_squared_error: 0.1645\n",
      "Epoch 80/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.1531 - mean_squared_error: 0.1531 - val_loss: 0.1640 - val_mean_squared_error: 0.1640\n",
      "Epoch 81/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.1534 - mean_squared_error: 0.1534 - val_loss: 0.1651 - val_mean_squared_error: 0.1651\n",
      "Epoch 82/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.1529 - mean_squared_error: 0.1529 - val_loss: 0.1659 - val_mean_squared_error: 0.1659\n",
      "Epoch 83/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.1528 - mean_squared_error: 0.1528 - val_loss: 0.1649 - val_mean_squared_error: 0.1649\n",
      "Epoch 84/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.1528 - mean_squared_error: 0.1528 - val_loss: 0.1644 - val_mean_squared_error: 0.1644\n",
      "Epoch 85/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.1528 - mean_squared_error: 0.1528 - val_loss: 0.1648 - val_mean_squared_error: 0.1648\n",
      "Epoch 86/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.1531 - mean_squared_error: 0.1531 - val_loss: 0.1653 - val_mean_squared_error: 0.1653\n",
      "Epoch 87/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.1529 - mean_squared_error: 0.1529 - val_loss: 0.1648 - val_mean_squared_error: 0.1648\n",
      "Epoch 88/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.1525 - mean_squared_error: 0.1525 - val_loss: 0.1647 - val_mean_squared_error: 0.1647\n",
      "Epoch 89/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.1525 - mean_squared_error: 0.1525 - val_loss: 0.1638 - val_mean_squared_error: 0.1638\n",
      "Epoch 90/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.1526 - mean_squared_error: 0.1526 - val_loss: 0.1643 - val_mean_squared_error: 0.1643\n",
      "Epoch 91/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.1524 - mean_squared_error: 0.1524 - val_loss: 0.1647 - val_mean_squared_error: 0.1647\n",
      "Epoch 92/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.1530 - mean_squared_error: 0.1530 - val_loss: 0.1641 - val_mean_squared_error: 0.1641\n",
      "Epoch 93/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.1525 - mean_squared_error: 0.1525 - val_loss: 0.1636 - val_mean_squared_error: 0.1636\n",
      "Epoch 94/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.1517 - mean_squared_error: 0.1517 - val_loss: 0.1639 - val_mean_squared_error: 0.1639\n",
      "Epoch 95/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.1518 - mean_squared_error: 0.1518 - val_loss: 0.1639 - val_mean_squared_error: 0.1639\n",
      "Epoch 96/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.1522 - mean_squared_error: 0.1522 - val_loss: 0.1648 - val_mean_squared_error: 0.1648\n",
      "Epoch 97/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.1518 - mean_squared_error: 0.1518 - val_loss: 0.1644 - val_mean_squared_error: 0.1644\n",
      "Epoch 98/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.1520 - mean_squared_error: 0.1520 - val_loss: 0.1640 - val_mean_squared_error: 0.1640\n",
      "Epoch 99/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.1518 - mean_squared_error: 0.1518 - val_loss: 0.1647 - val_mean_squared_error: 0.1647\n",
      "Epoch 100/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.1516 - mean_squared_error: 0.1516 - val_loss: 0.1642 - val_mean_squared_error: 0.1642\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff45589e7c0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_simple.fit(inputs_simple[:], expected_results[:,:,0], batch_size=64, \n",
    "                 epochs=100, verbose=1, validation_split=0.2) # validation loss keeps going down?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4552154 , 1.2252952 , 0.97599006, ..., 0.31898028, 0.2965657 ,\n",
       "        0.2526426 ],\n",
       "       [0.44509864, 1.2295414 , 0.98912084, ..., 0.33077532, 0.2958997 ,\n",
       "        0.26225537],\n",
       "       [0.42045796, 1.1442679 , 0.9264906 , ..., 0.32537568, 0.29542977,\n",
       "        0.26317954],\n",
       "       ...,\n",
       "       [0.49349552, 1.3570546 , 1.0625825 , ..., 0.32829818, 0.30296153,\n",
       "        0.25346696],\n",
       "       [0.2174711 , 0.66968983, 0.62520444, ..., 0.4198929 , 0.39894527,\n",
       "        0.43809325],\n",
       "       [0.4413795 , 1.1859127 , 0.92966163, ..., 0.3052482 , 0.28876698,\n",
       "        0.25437045]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_simple.predict(inputs_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_simple_test_public = preprocess_inputs(test_public,input_cols)\n",
    "inputs_simple_test_public = merge_inputs(inputs_simple_test_public, len(inputs_simple_test_public[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(629, 107, 14)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_simple_test_public.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.45530832, 1.2186967 , 0.9633015 , ..., 0.31342936, 0.29419202,\n",
       "        0.2520268 ],\n",
       "       [0.46435457, 1.2428504 , 0.98336935, ..., 0.31771863, 0.29673517,\n",
       "        0.25074688],\n",
       "       [0.4322242 , 1.1426079 , 0.8885317 , ..., 0.29964814, 0.2946388 ,\n",
       "        0.261455  ],\n",
       "       ...,\n",
       "       [0.5035448 , 1.4193052 , 1.0555708 , ..., 0.30375487, 0.29619753,\n",
       "        0.2677962 ],\n",
       "       [0.51145166, 1.4294422 , 1.0507143 , ..., 0.29762572, 0.2961886 ,\n",
       "        0.26806185],\n",
       "       [0.4339155 , 1.169026  , 0.9501978 , ..., 0.32281208, 0.29807135,\n",
       "        0.2560317 ]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_simple.predict(inputs_simple_test_public)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.3297,  1.5693,  1.1227, ...,  0.2937,  0.2362,  0.5731],\n",
       "       [ 0.4482,  1.4822,  1.1819, ...,  0.6449,  0.04  ,  0.5446],\n",
       "       [ 0.7642,  1.6641,  1.0622, ...,  0.1107,  0.2261,  0.3238],\n",
       "       ...,\n",
       "       [ 0.6957,  1.251 ,  1.3236, ..., -0.0043,  0.0521,  0.0874],\n",
       "       [ 0.2891,  0.4496,  0.7165, ...,  0.8738,  0.2816,  0.554 ],\n",
       "       [ 1.0102,  1.7928,  1.9228, ...,  0.0381, -0.0066,  0.0706]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_results[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4482, 0.2504, 0.5163, 2.243 , 0.9501],\n",
       "       [1.4822, 1.4021, 1.6823, 2.9361, 1.7975],\n",
       "       [1.1819, 0.9804, 1.0426, 1.0553, 1.4991],\n",
       "       [0.7434, 0.4967, 0.7902, 0.721 , 0.8686],\n",
       "       [0.7148, 0.3653, 0.7477, 0.6396, 0.6893],\n",
       "       [0.6529, 0.8973, 0.9697, 1.1473, 1.2293],\n",
       "       [0.2239, 0.296 , 0.2527, 0.3768, 0.3176],\n",
       "       [0.1927, 0.5758, 0.3151, 0.4777, 0.5927],\n",
       "       [0.1969, 0.7249, 0.8943, 0.9614, 0.8827],\n",
       "       [0.3033, 0.1514, 0.1396, 0.1522, 0.1861],\n",
       "       [0.6176, 0.2885, 0.5329, 0.3904, 0.4771],\n",
       "       [0.3858, 0.2239, 0.244 , 0.1389, 0.5338],\n",
       "       [1.0418, 0.9248, 0.796 , 0.4465, 0.7546],\n",
       "       [0.6581, 2.2196, 2.0522, 1.3107, 1.2277],\n",
       "       [1.1053, 0.7686, 0.8767, 0.7178, 0.7779],\n",
       "       [0.6224, 0.3331, 0.4773, 0.2121, 0.4945],\n",
       "       [0.4591, 0.32  , 0.1956, 0.1804, 0.4322],\n",
       "       [0.1989, 0.3516, 0.1778, 0.2019, 0.2082],\n",
       "       [0.1632, 1.3419, 1.0562, 0.5721, 0.6173],\n",
       "       [0.5538, 0.3321, 0.3052, 0.2512, 0.4662],\n",
       "       [0.6342, 0.6313, 0.3538, 0.2917, 0.4142],\n",
       "       [0.2547, 0.3432, 0.2953, 0.3454, 0.3651],\n",
       "       [0.1742, 0.351 , 0.1332, 0.1094, 0.027 ],\n",
       "       [0.2447, 0.469 , 0.3667, 0.4598, 0.4494],\n",
       "       [0.1331, 0.083 , 0.0964, 0.1127, 0.0372],\n",
       "       [0.0958, 0.0945, 0.1393, 0.1513, 0.3263],\n",
       "       [0.2976, 0.501 , 0.7581, 0.5245, 0.6954],\n",
       "       [0.4863, 0.4208, 0.3874, 0.4367, 0.5907],\n",
       "       [0.7058, 1.1765, 1.1231, 1.0301, 0.9179],\n",
       "       [0.4929, 0.7436, 0.3934, 0.5107, 0.4662],\n",
       "       [0.3874, 0.3218, 0.232 , 0.3339, 0.2485],\n",
       "       [0.1049, 0.3525, 0.2698, 0.2415, 0.2424],\n",
       "       [0.0915, 0.3936, 0.5047, 0.4625, 0.4754],\n",
       "       [0.349 , 0.2149, 0.2607, 0.2547, 0.4995],\n",
       "       [0.6972, 0.6345, 0.784 , 1.0076, 0.9001],\n",
       "       [0.0789, 0.1198, 0.1469, 0.1163, 0.0811],\n",
       "       [0.0442, 0.0892, 0.148 , 0.1334, 0.3837],\n",
       "       [0.29  , 0.421 , 0.5628, 0.5784, 0.8436],\n",
       "       [0.2542, 0.2882, 0.5339, 0.3149, 0.5387],\n",
       "       [0.8123, 0.9787, 1.2621, 0.8974, 1.0223],\n",
       "       [0.7938, 0.7306, 0.7705, 0.5722, 0.6264],\n",
       "       [0.2683, 0.3601, 0.5299, 0.3548, 0.3648],\n",
       "       [0.6897, 1.2572, 1.6268, 1.1298, 1.0223],\n",
       "       [0.4113, 0.4174, 0.4104, 0.4325, 0.5689],\n",
       "       [0.9513, 0.8092, 0.6241, 0.6031, 0.7289],\n",
       "       [0.1182, 0.1718, 0.1543, 0.1022, 0.139 ],\n",
       "       [0.0569, 0.1439, 0.1126, 0.1266, 0.2146],\n",
       "       [0.3467, 0.7986, 0.7567, 0.4616, 0.6872],\n",
       "       [0.3766, 0.1592, 0.085 , 0.0659, 0.1842],\n",
       "       [0.4152, 0.5368, 0.44  , 0.2205, 0.3691],\n",
       "       [0.8663, 1.6067, 1.064 , 0.6645, 0.4583],\n",
       "       [0.5321, 0.9046, 0.5904, 0.4801, 0.4626],\n",
       "       [0.5652, 0.4441, 0.4004, 0.3718, 0.6801],\n",
       "       [0.0862, 0.4018, 0.6977, 0.6547, 0.5281],\n",
       "       [0.0991, 0.1968, 0.2067, 0.3286, 0.4799],\n",
       "       [0.4442, 0.4193, 0.4357, 0.6764, 0.9201],\n",
       "       [0.0885, 0.088 , 0.1093, 0.0913, 0.1077],\n",
       "       [0.0444, 0.1465, 0.1759, 0.2582, 0.2639],\n",
       "       [0.1425, 0.206 , 0.1699, 0.2359, 0.2674],\n",
       "       [0.355 , 0.4417, 0.4814, 0.4167, 0.4052],\n",
       "       [0.3352, 0.5223, 0.4042, 0.5331, 0.7162],\n",
       "       [0.2804, 0.8147, 0.8475, 0.8424, 0.6113],\n",
       "       [0.3229, 0.5025, 0.4499, 0.4813, 0.6801],\n",
       "       [0.8048, 1.2544, 1.085 , 0.8364, 0.9186],\n",
       "       [0.3103, 0.6633, 0.5934, 0.3811, 0.4832],\n",
       "       [0.6449, 1.6819, 1.464 , 1.0621, 0.7789],\n",
       "       [0.04  , 0.5367, 0.4201, 0.4391, 0.3348],\n",
       "       [0.5446, 1.24  , 0.8575, 1.0076, 0.5827]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_results[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq (InputLayer)                [(None, None, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pair (InputLayer)               [(None, None, 3)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "loop (InputLayer)               [(None, None, 7)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, None, 10)     130         seq[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, None, 10)     100         pair[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, None, 10)     220         loop[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 10)           0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 10)           0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_3 (GlobalM (None, 10)           0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 20)           220         global_max_pooling1d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 20)           220         global_max_pooling1d_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 20)           220         global_max_pooling1d_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 60)           0           dense_4[0][0]                    \n",
      "                                                                 dense_5[0][0]                    \n",
      "                                                                 dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 60)           0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reactivity (Dense)              (None, 68)           4148        flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "deg_Mg_pH10 (Dense)             (None, 68)           4148        flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "deg_Mg_50C (Dense)              (None, 68)           4148        flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "deg_pH10 (Dense)                (None, 68)           4148        flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "deg_50C (Dense)                 (None, 68)           4148        flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 21,850\n",
      "Trainable params: 21,850\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seq_input = keras.layers.Input(shape=(None,4), name=\"seq\")      #Input shape a revoir\n",
    "pair_input = keras.layers.Input(shape=(None,3), name=\"pair\")  \n",
    "loop_input = keras.layers.Input(shape=(None,7), name=\"loop\")  \n",
    "\n",
    "seq_features = keras.layers.Conv1D(filters=10, kernel_size=3, activation=('relu'), \n",
    "                                     padding='same')(seq_input)\n",
    "pair_features = keras.layers.Conv1D(filters=10, kernel_size=3, activation=('relu'), \n",
    "                                     padding='same')(pair_input)\n",
    "loop_features = keras.layers.Conv1D(filters=10, kernel_size=3, activation=('relu'), \n",
    "                                     padding='same')(loop_input)\n",
    "\n",
    "seq_features = keras.layers.GlobalMaxPooling1D()(seq_features)\n",
    "pair_features = keras.layers.GlobalMaxPooling1D()(pair_features)\n",
    "loop_features = keras.layers.GlobalMaxPooling1D()(loop_features)\n",
    "\n",
    "seq_features = keras.layers.Dense(20)(seq_features)\n",
    "pair_features = keras.layers.Dense(20)(pair_features)\n",
    "loop_features = keras.layers.Dense(20)(loop_features)\n",
    "\n",
    "\n",
    "# Merge les features\n",
    "x = keras.layers.concatenate([seq_features, pair_features, loop_features])\n",
    "\n",
    "flat = keras.layers.Flatten()(x)\n",
    "\n",
    "first_pred = keras.layers.Dense(68, name=\"reactivity\")(flat) #regression pour \"reactivity\"\n",
    "second_pred = keras.layers.Dense(68, name=\"deg_Mg_pH10\")(flat)  #regression pour \"ph\"\n",
    "third_pred = keras.layers.Dense(68, name=\"deg_Mg_50C\")(flat)\n",
    "fourth_pred = keras.layers.Dense(68, name=\"deg_pH10\")(flat)\n",
    "fifth_pred = keras.layers.Dense(68, name=\"deg_50C\")(flat)\n",
    "\n",
    "\n",
    "model = keras.Model(\n",
    "    inputs=[seq_input, pair_input, loop_input],\n",
    "    outputs=[first_pred, second_pred, third_pred, fourth_pred, fifth_pred],\n",
    ")\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "51/51 [==============================] - 1s 15ms/step - loss: 1.6196 - reactivity_loss: 0.2969 - deg_Mg_pH10_loss: 0.3513 - deg_Mg_50C_loss: 0.2941 - deg_pH10_loss: 0.4167 - deg_50C_loss: 0.2606 - reactivity_mse: 0.2969 - deg_Mg_pH10_mse: 0.3513 - deg_Mg_50C_mse: 0.2941 - deg_pH10_mse: 0.4167 - deg_50C_mse: 0.2606 - val_loss: 0.9720 - val_reactivity_loss: 0.1905 - val_deg_Mg_pH10_loss: 0.2258 - val_deg_Mg_50C_loss: 0.1858 - val_deg_pH10_loss: 0.2284 - val_deg_50C_loss: 0.1415 - val_reactivity_mse: 0.1905 - val_deg_Mg_pH10_mse: 0.2258 - val_deg_Mg_50C_mse: 0.1858 - val_deg_pH10_mse: 0.2284 - val_deg_50C_mse: 0.1415\n",
      "Epoch 2/30\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 0.8765 - reactivity_loss: 0.1708 - deg_Mg_pH10_loss: 0.2137 - deg_Mg_50C_loss: 0.1776 - deg_pH10_loss: 0.1832 - deg_50C_loss: 0.1311 - reactivity_mse: 0.1708 - deg_Mg_pH10_mse: 0.2137 - deg_Mg_50C_mse: 0.1776 - deg_pH10_mse: 0.1832 - deg_50C_mse: 0.1311 - val_loss: 0.8418 - val_reactivity_loss: 0.1666 - val_deg_Mg_pH10_loss: 0.2113 - val_deg_Mg_50C_loss: 0.1729 - val_deg_pH10_loss: 0.1605 - val_deg_50C_loss: 0.1305 - val_reactivity_mse: 0.1666 - val_deg_Mg_pH10_mse: 0.2113 - val_deg_Mg_50C_mse: 0.1729 - val_deg_pH10_mse: 0.1605 - val_deg_50C_mse: 0.1305\n",
      "Epoch 3/30\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 0.8302 - reactivity_loss: 0.1632 - deg_Mg_pH10_loss: 0.2099 - deg_Mg_50C_loss: 0.1731 - deg_pH10_loss: 0.1567 - deg_50C_loss: 0.1274 - reactivity_mse: 0.1632 - deg_Mg_pH10_mse: 0.2099 - deg_Mg_50C_mse: 0.1731 - deg_pH10_mse: 0.1567 - deg_50C_mse: 0.1274 - val_loss: 0.8318 - val_reactivity_loss: 0.1651 - val_deg_Mg_pH10_loss: 0.2110 - val_deg_Mg_50C_loss: 0.1717 - val_deg_pH10_loss: 0.1546 - val_deg_50C_loss: 0.1294 - val_reactivity_mse: 0.1651 - val_deg_Mg_pH10_mse: 0.2110 - val_deg_Mg_50C_mse: 0.1717 - val_deg_pH10_mse: 0.1546 - val_deg_50C_mse: 0.1294\n",
      "Epoch 4/30\n",
      "51/51 [==============================] - 1s 20ms/step - loss: 0.8240 - reactivity_loss: 0.1626 - deg_Mg_pH10_loss: 0.2094 - deg_Mg_50C_loss: 0.1718 - deg_pH10_loss: 0.1540 - deg_50C_loss: 0.1262 - reactivity_mse: 0.1626 - deg_Mg_pH10_mse: 0.2094 - deg_Mg_50C_mse: 0.1718 - deg_pH10_mse: 0.1540 - deg_50C_mse: 0.1262 - val_loss: 0.8267 - val_reactivity_loss: 0.1643 - val_deg_Mg_pH10_loss: 0.2103 - val_deg_Mg_50C_loss: 0.1704 - val_deg_pH10_loss: 0.1536 - val_deg_50C_loss: 0.1281 - val_reactivity_mse: 0.1643 - val_deg_Mg_pH10_mse: 0.2103 - val_deg_Mg_50C_mse: 0.1704 - val_deg_pH10_mse: 0.1536 - val_deg_50C_mse: 0.1281\n",
      "Epoch 5/30\n",
      "51/51 [==============================] - 1s 10ms/step - loss: 0.8202 - reactivity_loss: 0.1618 - deg_Mg_pH10_loss: 0.2090 - deg_Mg_50C_loss: 0.1709 - deg_pH10_loss: 0.1531 - deg_50C_loss: 0.1254 - reactivity_mse: 0.1618 - deg_Mg_pH10_mse: 0.2090 - deg_Mg_50C_mse: 0.1709 - deg_pH10_mse: 0.1531 - deg_50C_mse: 0.1254 - val_loss: 0.8230 - val_reactivity_loss: 0.1640 - val_deg_Mg_pH10_loss: 0.2097 - val_deg_Mg_50C_loss: 0.1693 - val_deg_pH10_loss: 0.1525 - val_deg_50C_loss: 0.1275 - val_reactivity_mse: 0.1640 - val_deg_Mg_pH10_mse: 0.2097 - val_deg_Mg_50C_mse: 0.1693 - val_deg_pH10_mse: 0.1525 - val_deg_50C_mse: 0.1275\n",
      "Epoch 6/30\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 0.8170 - reactivity_loss: 0.1612 - deg_Mg_pH10_loss: 0.2086 - deg_Mg_50C_loss: 0.1703 - deg_pH10_loss: 0.1523 - deg_50C_loss: 0.1247 - reactivity_mse: 0.1612 - deg_Mg_pH10_mse: 0.2086 - deg_Mg_50C_mse: 0.1703 - deg_pH10_mse: 0.1523 - deg_50C_mse: 0.1247 - val_loss: 0.8225 - val_reactivity_loss: 0.1637 - val_deg_Mg_pH10_loss: 0.2098 - val_deg_Mg_50C_loss: 0.1696 - val_deg_pH10_loss: 0.1521 - val_deg_50C_loss: 0.1274 - val_reactivity_mse: 0.1637 - val_deg_Mg_pH10_mse: 0.2098 - val_deg_Mg_50C_mse: 0.1696 - val_deg_pH10_mse: 0.1521 - val_deg_50C_mse: 0.1274\n",
      "Epoch 7/30\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 0.8140 - reactivity_loss: 0.1606 - deg_Mg_pH10_loss: 0.2080 - deg_Mg_50C_loss: 0.1696 - deg_pH10_loss: 0.1516 - deg_50C_loss: 0.1242 - reactivity_mse: 0.1606 - deg_Mg_pH10_mse: 0.2080 - deg_Mg_50C_mse: 0.1696 - deg_pH10_mse: 0.1516 - deg_50C_mse: 0.1242 - val_loss: 0.8219 - val_reactivity_loss: 0.1641 - val_deg_Mg_pH10_loss: 0.2099 - val_deg_Mg_50C_loss: 0.1695 - val_deg_pH10_loss: 0.1517 - val_deg_50C_loss: 0.1267 - val_reactivity_mse: 0.1641 - val_deg_Mg_pH10_mse: 0.2099 - val_deg_Mg_50C_mse: 0.1695 - val_deg_pH10_mse: 0.1517 - val_deg_50C_mse: 0.1267\n",
      "Epoch 8/30\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 0.8115 - reactivity_loss: 0.1603 - deg_Mg_pH10_loss: 0.2077 - deg_Mg_50C_loss: 0.1690 - deg_pH10_loss: 0.1510 - deg_50C_loss: 0.1235 - reactivity_mse: 0.1603 - deg_Mg_pH10_mse: 0.2077 - deg_Mg_50C_mse: 0.1690 - deg_pH10_mse: 0.1510 - deg_50C_mse: 0.1235 - val_loss: 0.8176 - val_reactivity_loss: 0.1630 - val_deg_Mg_pH10_loss: 0.2091 - val_deg_Mg_50C_loss: 0.1685 - val_deg_pH10_loss: 0.1513 - val_deg_50C_loss: 0.1257 - val_reactivity_mse: 0.1630 - val_deg_Mg_pH10_mse: 0.2091 - val_deg_Mg_50C_mse: 0.1685 - val_deg_pH10_mse: 0.1513 - val_deg_50C_mse: 0.1257\n",
      "Epoch 9/30\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 0.8102 - reactivity_loss: 0.1600 - deg_Mg_pH10_loss: 0.2075 - deg_Mg_50C_loss: 0.1688 - deg_pH10_loss: 0.1507 - deg_50C_loss: 0.1233 - reactivity_mse: 0.1600 - deg_Mg_pH10_mse: 0.2075 - deg_Mg_50C_mse: 0.1688 - deg_pH10_mse: 0.1507 - deg_50C_mse: 0.1233 - val_loss: 0.8155 - val_reactivity_loss: 0.1626 - val_deg_Mg_pH10_loss: 0.2085 - val_deg_Mg_50C_loss: 0.1681 - val_deg_pH10_loss: 0.1504 - val_deg_50C_loss: 0.1258 - val_reactivity_mse: 0.1626 - val_deg_Mg_pH10_mse: 0.2085 - val_deg_Mg_50C_mse: 0.1681 - val_deg_pH10_mse: 0.1504 - val_deg_50C_mse: 0.1258\n",
      "Epoch 10/30\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 0.8076 - reactivity_loss: 0.1595 - deg_Mg_pH10_loss: 0.2069 - deg_Mg_50C_loss: 0.1682 - deg_pH10_loss: 0.1503 - deg_50C_loss: 0.1228 - reactivity_mse: 0.1595 - deg_Mg_pH10_mse: 0.2069 - deg_Mg_50C_mse: 0.1682 - deg_pH10_mse: 0.1503 - deg_50C_mse: 0.1228 - val_loss: 0.8132 - val_reactivity_loss: 0.1621 - val_deg_Mg_pH10_loss: 0.2084 - val_deg_Mg_50C_loss: 0.1674 - val_deg_pH10_loss: 0.1503 - val_deg_50C_loss: 0.1251 - val_reactivity_mse: 0.1621 - val_deg_Mg_pH10_mse: 0.2084 - val_deg_Mg_50C_mse: 0.1674 - val_deg_pH10_mse: 0.1503 - val_deg_50C_mse: 0.1251\n",
      "Epoch 11/30\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 0.8054 - reactivity_loss: 0.1589 - deg_Mg_pH10_loss: 0.2066 - deg_Mg_50C_loss: 0.1678 - deg_pH10_loss: 0.1498 - deg_50C_loss: 0.1222 - reactivity_mse: 0.1589 - deg_Mg_pH10_mse: 0.2066 - deg_Mg_50C_mse: 0.1678 - deg_pH10_mse: 0.1498 - deg_50C_mse: 0.1222 - val_loss: 0.8121 - val_reactivity_loss: 0.1618 - val_deg_Mg_pH10_loss: 0.2081 - val_deg_Mg_50C_loss: 0.1673 - val_deg_pH10_loss: 0.1500 - val_deg_50C_loss: 0.1249 - val_reactivity_mse: 0.1618 - val_deg_Mg_pH10_mse: 0.2081 - val_deg_Mg_50C_mse: 0.1673 - val_deg_pH10_mse: 0.1500 - val_deg_50C_mse: 0.1249\n",
      "Epoch 12/30\n",
      "51/51 [==============================] - 0s 9ms/step - loss: 0.8035 - reactivity_loss: 0.1585 - deg_Mg_pH10_loss: 0.2064 - deg_Mg_50C_loss: 0.1674 - deg_pH10_loss: 0.1495 - deg_50C_loss: 0.1218 - reactivity_mse: 0.1585 - deg_Mg_pH10_mse: 0.2064 - deg_Mg_50C_mse: 0.1674 - deg_pH10_mse: 0.1495 - deg_50C_mse: 0.1218 - val_loss: 0.8083 - val_reactivity_loss: 0.1609 - val_deg_Mg_pH10_loss: 0.2076 - val_deg_Mg_50C_loss: 0.1665 - val_deg_pH10_loss: 0.1495 - val_deg_50C_loss: 0.1239 - val_reactivity_mse: 0.1609 - val_deg_Mg_pH10_mse: 0.2076 - val_deg_Mg_50C_mse: 0.1665 - val_deg_pH10_mse: 0.1495 - val_deg_50C_mse: 0.1239\n",
      "Epoch 13/30\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 0.8009 - reactivity_loss: 0.1580 - deg_Mg_pH10_loss: 0.2057 - deg_Mg_50C_loss: 0.1668 - deg_pH10_loss: 0.1491 - deg_50C_loss: 0.1212 - reactivity_mse: 0.1580 - deg_Mg_pH10_mse: 0.2057 - deg_Mg_50C_mse: 0.1668 - deg_pH10_mse: 0.1491 - deg_50C_mse: 0.1212 - val_loss: 0.8062 - val_reactivity_loss: 0.1609 - val_deg_Mg_pH10_loss: 0.2068 - val_deg_Mg_50C_loss: 0.1657 - val_deg_pH10_loss: 0.1493 - val_deg_50C_loss: 0.1235 - val_reactivity_mse: 0.1609 - val_deg_Mg_pH10_mse: 0.2068 - val_deg_Mg_50C_mse: 0.1657 - val_deg_pH10_mse: 0.1493 - val_deg_50C_mse: 0.1235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 0.7976 - reactivity_loss: 0.1575 - deg_Mg_pH10_loss: 0.2050 - deg_Mg_50C_loss: 0.1660 - deg_pH10_loss: 0.1485 - deg_50C_loss: 0.1206 - reactivity_mse: 0.1575 - deg_Mg_pH10_mse: 0.2050 - deg_Mg_50C_mse: 0.1660 - deg_pH10_mse: 0.1485 - deg_50C_mse: 0.1206 - val_loss: 0.8060 - val_reactivity_loss: 0.1602 - val_deg_Mg_pH10_loss: 0.2070 - val_deg_Mg_50C_loss: 0.1660 - val_deg_pH10_loss: 0.1492 - val_deg_50C_loss: 0.1236 - val_reactivity_mse: 0.1602 - val_deg_Mg_pH10_mse: 0.2070 - val_deg_Mg_50C_mse: 0.1660 - val_deg_pH10_mse: 0.1492 - val_deg_50C_mse: 0.1236\n",
      "Epoch 15/30\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.7951 - reactivity_loss: 0.1569 - deg_Mg_pH10_loss: 0.2045 - deg_Mg_50C_loss: 0.1654 - deg_pH10_loss: 0.1482 - deg_50C_loss: 0.1201 - reactivity_mse: 0.1569 - deg_Mg_pH10_mse: 0.2045 - deg_Mg_50C_mse: 0.1654 - deg_pH10_mse: 0.1482 - deg_50C_mse: 0.1201 - val_loss: 0.8024 - val_reactivity_loss: 0.1597 - val_deg_Mg_pH10_loss: 0.2064 - val_deg_Mg_50C_loss: 0.1650 - val_deg_pH10_loss: 0.1486 - val_deg_50C_loss: 0.1227 - val_reactivity_mse: 0.1597 - val_deg_Mg_pH10_mse: 0.2064 - val_deg_Mg_50C_mse: 0.1650 - val_deg_pH10_mse: 0.1486 - val_deg_50C_mse: 0.1227\n",
      "Epoch 16/30\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.7926 - reactivity_loss: 0.1563 - deg_Mg_pH10_loss: 0.2040 - deg_Mg_50C_loss: 0.1649 - deg_pH10_loss: 0.1476 - deg_50C_loss: 0.1197 - reactivity_mse: 0.1563 - deg_Mg_pH10_mse: 0.2040 - deg_Mg_50C_mse: 0.1649 - deg_pH10_mse: 0.1476 - deg_50C_mse: 0.1197 - val_loss: 0.8019 - val_reactivity_loss: 0.1591 - val_deg_Mg_pH10_loss: 0.2060 - val_deg_Mg_50C_loss: 0.1656 - val_deg_pH10_loss: 0.1481 - val_deg_50C_loss: 0.1230 - val_reactivity_mse: 0.1591 - val_deg_Mg_pH10_mse: 0.2060 - val_deg_Mg_50C_mse: 0.1656 - val_deg_pH10_mse: 0.1481 - val_deg_50C_mse: 0.1230\n",
      "Epoch 17/30\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.7909 - reactivity_loss: 0.1561 - deg_Mg_pH10_loss: 0.2035 - deg_Mg_50C_loss: 0.1645 - deg_pH10_loss: 0.1474 - deg_50C_loss: 0.1194 - reactivity_mse: 0.1561 - deg_Mg_pH10_mse: 0.2035 - deg_Mg_50C_mse: 0.1645 - deg_pH10_mse: 0.1474 - deg_50C_mse: 0.1194 - val_loss: 0.7984 - val_reactivity_loss: 0.1589 - val_deg_Mg_pH10_loss: 0.2051 - val_deg_Mg_50C_loss: 0.1644 - val_deg_pH10_loss: 0.1476 - val_deg_50C_loss: 0.1223 - val_reactivity_mse: 0.1589 - val_deg_Mg_pH10_mse: 0.2051 - val_deg_Mg_50C_mse: 0.1644 - val_deg_pH10_mse: 0.1476 - val_deg_50C_mse: 0.1223\n",
      "Epoch 18/30\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.7879 - reactivity_loss: 0.1555 - deg_Mg_pH10_loss: 0.2029 - deg_Mg_50C_loss: 0.1637 - deg_pH10_loss: 0.1469 - deg_50C_loss: 0.1190 - reactivity_mse: 0.1555 - deg_Mg_pH10_mse: 0.2029 - deg_Mg_50C_mse: 0.1637 - deg_pH10_mse: 0.1469 - deg_50C_mse: 0.1190 - val_loss: 0.7959 - val_reactivity_loss: 0.1587 - val_deg_Mg_pH10_loss: 0.2049 - val_deg_Mg_50C_loss: 0.1636 - val_deg_pH10_loss: 0.1472 - val_deg_50C_loss: 0.1215 - val_reactivity_mse: 0.1587 - val_deg_Mg_pH10_mse: 0.2049 - val_deg_Mg_50C_mse: 0.1636 - val_deg_pH10_mse: 0.1472 - val_deg_50C_mse: 0.1215\n",
      "Epoch 19/30\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.7861 - reactivity_loss: 0.1550 - deg_Mg_pH10_loss: 0.2025 - deg_Mg_50C_loss: 0.1633 - deg_pH10_loss: 0.1466 - deg_50C_loss: 0.1187 - reactivity_mse: 0.1550 - deg_Mg_pH10_mse: 0.2025 - deg_Mg_50C_mse: 0.1633 - deg_pH10_mse: 0.1466 - deg_50C_mse: 0.1187 - val_loss: 0.7972 - val_reactivity_loss: 0.1589 - val_deg_Mg_pH10_loss: 0.2047 - val_deg_Mg_50C_loss: 0.1639 - val_deg_pH10_loss: 0.1475 - val_deg_50C_loss: 0.1222 - val_reactivity_mse: 0.1589 - val_deg_Mg_pH10_mse: 0.2047 - val_deg_Mg_50C_mse: 0.1639 - val_deg_pH10_mse: 0.1475 - val_deg_50C_mse: 0.1222\n",
      "Epoch 20/30\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.7851 - reactivity_loss: 0.1547 - deg_Mg_pH10_loss: 0.2021 - deg_Mg_50C_loss: 0.1632 - deg_pH10_loss: 0.1464 - deg_50C_loss: 0.1187 - reactivity_mse: 0.1547 - deg_Mg_pH10_mse: 0.2021 - deg_Mg_50C_mse: 0.1632 - deg_pH10_mse: 0.1464 - deg_50C_mse: 0.1187 - val_loss: 0.7948 - val_reactivity_loss: 0.1587 - val_deg_Mg_pH10_loss: 0.2044 - val_deg_Mg_50C_loss: 0.1630 - val_deg_pH10_loss: 0.1470 - val_deg_50C_loss: 0.1217 - val_reactivity_mse: 0.1587 - val_deg_Mg_pH10_mse: 0.2044 - val_deg_Mg_50C_mse: 0.1630 - val_deg_pH10_mse: 0.1470 - val_deg_50C_mse: 0.1217\n",
      "Epoch 21/30\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.7830 - reactivity_loss: 0.1542 - deg_Mg_pH10_loss: 0.2017 - deg_Mg_50C_loss: 0.1627 - deg_pH10_loss: 0.1460 - deg_50C_loss: 0.1183 - reactivity_mse: 0.1542 - deg_Mg_pH10_mse: 0.2017 - deg_Mg_50C_mse: 0.1627 - deg_pH10_mse: 0.1460 - deg_50C_mse: 0.1183 - val_loss: 0.7924 - val_reactivity_loss: 0.1580 - val_deg_Mg_pH10_loss: 0.2040 - val_deg_Mg_50C_loss: 0.1626 - val_deg_pH10_loss: 0.1464 - val_deg_50C_loss: 0.1213 - val_reactivity_mse: 0.1580 - val_deg_Mg_pH10_mse: 0.2040 - val_deg_Mg_50C_mse: 0.1626 - val_deg_pH10_mse: 0.1464 - val_deg_50C_mse: 0.1213\n",
      "Epoch 22/30\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.7808 - reactivity_loss: 0.1539 - deg_Mg_pH10_loss: 0.2013 - deg_Mg_50C_loss: 0.1622 - deg_pH10_loss: 0.1456 - deg_50C_loss: 0.1178 - reactivity_mse: 0.1539 - deg_Mg_pH10_mse: 0.2013 - deg_Mg_50C_mse: 0.1622 - deg_pH10_mse: 0.1456 - deg_50C_mse: 0.1178 - val_loss: 0.7918 - val_reactivity_loss: 0.1575 - val_deg_Mg_pH10_loss: 0.2034 - val_deg_Mg_50C_loss: 0.1628 - val_deg_pH10_loss: 0.1464 - val_deg_50C_loss: 0.1218 - val_reactivity_mse: 0.1575 - val_deg_Mg_pH10_mse: 0.2034 - val_deg_Mg_50C_mse: 0.1628 - val_deg_pH10_mse: 0.1464 - val_deg_50C_mse: 0.1218\n",
      "Epoch 23/30\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.7801 - reactivity_loss: 0.1537 - deg_Mg_pH10_loss: 0.2010 - deg_Mg_50C_loss: 0.1620 - deg_pH10_loss: 0.1455 - deg_50C_loss: 0.1178 - reactivity_mse: 0.1537 - deg_Mg_pH10_mse: 0.2010 - deg_Mg_50C_mse: 0.1620 - deg_pH10_mse: 0.1455 - deg_50C_mse: 0.1178 - val_loss: 0.7875 - val_reactivity_loss: 0.1571 - val_deg_Mg_pH10_loss: 0.2027 - val_deg_Mg_50C_loss: 0.1615 - val_deg_pH10_loss: 0.1458 - val_deg_50C_loss: 0.1203 - val_reactivity_mse: 0.1571 - val_deg_Mg_pH10_mse: 0.2027 - val_deg_Mg_50C_mse: 0.1615 - val_deg_pH10_mse: 0.1458 - val_deg_50C_mse: 0.1203\n",
      "Epoch 24/30\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.7779 - reactivity_loss: 0.1532 - deg_Mg_pH10_loss: 0.2006 - deg_Mg_50C_loss: 0.1616 - deg_pH10_loss: 0.1451 - deg_50C_loss: 0.1175 - reactivity_mse: 0.1532 - deg_Mg_pH10_mse: 0.2006 - deg_Mg_50C_mse: 0.1616 - deg_pH10_mse: 0.1451 - deg_50C_mse: 0.1175 - val_loss: 0.7909 - val_reactivity_loss: 0.1575 - val_deg_Mg_pH10_loss: 0.2034 - val_deg_Mg_50C_loss: 0.1623 - val_deg_pH10_loss: 0.1463 - val_deg_50C_loss: 0.1214 - val_reactivity_mse: 0.1575 - val_deg_Mg_pH10_mse: 0.2034 - val_deg_Mg_50C_mse: 0.1623 - val_deg_pH10_mse: 0.1463 - val_deg_50C_mse: 0.1214\n",
      "Epoch 25/30\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.7768 - reactivity_loss: 0.1529 - deg_Mg_pH10_loss: 0.2003 - deg_Mg_50C_loss: 0.1614 - deg_pH10_loss: 0.1448 - deg_50C_loss: 0.1173 - reactivity_mse: 0.1529 - deg_Mg_pH10_mse: 0.2003 - deg_Mg_50C_mse: 0.1614 - deg_pH10_mse: 0.1448 - deg_50C_mse: 0.1173 - val_loss: 0.7877 - val_reactivity_loss: 0.1571 - val_deg_Mg_pH10_loss: 0.2025 - val_deg_Mg_50C_loss: 0.1615 - val_deg_pH10_loss: 0.1456 - val_deg_50C_loss: 0.1209 - val_reactivity_mse: 0.1571 - val_deg_Mg_pH10_mse: 0.2025 - val_deg_Mg_50C_mse: 0.1615 - val_deg_pH10_mse: 0.1456 - val_deg_50C_mse: 0.1209\n",
      "Epoch 26/30\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.7745 - reactivity_loss: 0.1525 - deg_Mg_pH10_loss: 0.1997 - deg_Mg_50C_loss: 0.1608 - deg_pH10_loss: 0.1445 - deg_50C_loss: 0.1170 - reactivity_mse: 0.1525 - deg_Mg_pH10_mse: 0.1997 - deg_Mg_50C_mse: 0.1608 - deg_pH10_mse: 0.1445 - deg_50C_mse: 0.1170 - val_loss: 0.7874 - val_reactivity_loss: 0.1568 - val_deg_Mg_pH10_loss: 0.2027 - val_deg_Mg_50C_loss: 0.1618 - val_deg_pH10_loss: 0.1455 - val_deg_50C_loss: 0.1206 - val_reactivity_mse: 0.1568 - val_deg_Mg_pH10_mse: 0.2027 - val_deg_Mg_50C_mse: 0.1618 - val_deg_pH10_mse: 0.1455 - val_deg_50C_mse: 0.1206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.7739 - reactivity_loss: 0.1523 - deg_Mg_pH10_loss: 0.1996 - deg_Mg_50C_loss: 0.1607 - deg_pH10_loss: 0.1443 - deg_50C_loss: 0.1170 - reactivity_mse: 0.1523 - deg_Mg_pH10_mse: 0.1996 - deg_Mg_50C_mse: 0.1607 - deg_pH10_mse: 0.1443 - deg_50C_mse: 0.1170 - val_loss: 0.7858 - val_reactivity_loss: 0.1564 - val_deg_Mg_pH10_loss: 0.2023 - val_deg_Mg_50C_loss: 0.1612 - val_deg_pH10_loss: 0.1455 - val_deg_50C_loss: 0.1204 - val_reactivity_mse: 0.1564 - val_deg_Mg_pH10_mse: 0.2023 - val_deg_Mg_50C_mse: 0.1612 - val_deg_pH10_mse: 0.1455 - val_deg_50C_mse: 0.1204\n",
      "Epoch 28/30\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.7717 - reactivity_loss: 0.1519 - deg_Mg_pH10_loss: 0.1992 - deg_Mg_50C_loss: 0.1601 - deg_pH10_loss: 0.1439 - deg_50C_loss: 0.1166 - reactivity_mse: 0.1519 - deg_Mg_pH10_mse: 0.1992 - deg_Mg_50C_mse: 0.1601 - deg_pH10_mse: 0.1439 - deg_50C_mse: 0.1166 - val_loss: 0.7878 - val_reactivity_loss: 0.1570 - val_deg_Mg_pH10_loss: 0.2025 - val_deg_Mg_50C_loss: 0.1616 - val_deg_pH10_loss: 0.1458 - val_deg_50C_loss: 0.1209 - val_reactivity_mse: 0.1570 - val_deg_Mg_pH10_mse: 0.2025 - val_deg_Mg_50C_mse: 0.1616 - val_deg_pH10_mse: 0.1458 - val_deg_50C_mse: 0.1209\n",
      "Epoch 29/30\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 0.7713 - reactivity_loss: 0.1518 - deg_Mg_pH10_loss: 0.1990 - deg_Mg_50C_loss: 0.1602 - deg_pH10_loss: 0.1438 - deg_50C_loss: 0.1165 - reactivity_mse: 0.1518 - deg_Mg_pH10_mse: 0.1990 - deg_Mg_50C_mse: 0.1602 - deg_pH10_mse: 0.1438 - deg_50C_mse: 0.1165 - val_loss: 0.7862 - val_reactivity_loss: 0.1565 - val_deg_Mg_pH10_loss: 0.2022 - val_deg_Mg_50C_loss: 0.1614 - val_deg_pH10_loss: 0.1454 - val_deg_50C_loss: 0.1206 - val_reactivity_mse: 0.1565 - val_deg_Mg_pH10_mse: 0.2022 - val_deg_Mg_50C_mse: 0.1614 - val_deg_pH10_mse: 0.1454 - val_deg_50C_mse: 0.1206\n",
      "Epoch 30/30\n",
      "51/51 [==============================] - 1s 13ms/step - loss: 0.7701 - reactivity_loss: 0.1516 - deg_Mg_pH10_loss: 0.1985 - deg_Mg_50C_loss: 0.1598 - deg_pH10_loss: 0.1437 - deg_50C_loss: 0.1166 - reactivity_mse: 0.1516 - deg_Mg_pH10_mse: 0.1985 - deg_Mg_50C_mse: 0.1598 - deg_pH10_mse: 0.1437 - deg_50C_mse: 0.1166 - val_loss: 0.7826 - val_reactivity_loss: 0.1559 - val_deg_Mg_pH10_loss: 0.2017 - val_deg_Mg_50C_loss: 0.1606 - val_deg_pH10_loss: 0.1447 - val_deg_50C_loss: 0.1197 - val_reactivity_mse: 0.1559 - val_deg_Mg_pH10_mse: 0.2017 - val_deg_Mg_50C_mse: 0.1606 - val_deg_pH10_mse: 0.1447 - val_deg_50C_mse: 0.1197\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff45ba10fd0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([inputs_simple[:,:,0:4], inputs_simple[:,:,4:7], inputs_simple[:,:,7:14]],\n",
    "          [expected_results[:,:,0], expected_results[:,:,1], expected_results[:,:,2],\n",
    "          expected_results[:,:,3], expected_results[:,:,4]], batch_size = 25, \n",
    "          epochs = 30, verbose = 1, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_simple[0,0,0:4]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Revoir donnees a predire**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
